{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "revised sih project (02/02/2020)",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pj_p7keBqPD",
        "colab_type": "text"
      },
      "source": [
        "To mount the drive to colab, if you dont want to use colab skip this step and the next step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go8APqxNBoZp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db2e1efa-be0a-456e-ba81-8bc9aee7dfe2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS2bQ_E1BZFv",
        "colab_type": "text"
      },
      "source": [
        "This is to unzip the file in drive(run this only once or if your drive has a unzipped file)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DigvoXK-CNYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/drive/My Drive/traffic_signs/zipped.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCLFEB34C-LU",
        "colab_type": "text"
      },
      "source": [
        "These are all the imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M2_wx38YtpWQ",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sqrt, ceil\n",
        "from timeit import default_timer as timer\n",
        "import random\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, Reshape\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras import backend as K\n",
        "import os\n",
        "import cv2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg2coc4nDhJs",
        "colab_type": "text"
      },
      "source": [
        "This part of the code loads and preprosses the data . images is a numpy ndarray that takes in all the images of all labels, Notice that ive used 13 labels and not 43. I have created my own dataset and appended it to the original dataset. (to see how i did that see my preprosing.ipynb file) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pM14yWMvtpWM",
        "colab": {}
      },
      "source": [
        "path = \"/content/drive/My Drive/traffic_signs/datasets\" # folder with all the class folders\n",
        "labelFile = 'labels.csv' # file with all names of classes\n",
        "count = 0\n",
        "images = []\n",
        "classNo = []\n",
        "myList = os.listdir(path)\n",
        "print(\"Total Classes Detected:\",len(myList))\n",
        "noOfClasses=len(myList)\n",
        "print(\"Importing Classes.....\")\n",
        "for x in range (0,len(myList)):\n",
        "    myPicList = os.listdir(path+\"/\"+str(count))\n",
        "    for y in myPicList:\n",
        "        curImg = cv2.imread(path+\"/\"+str(count)+\"/\"+y)\n",
        "        grayImage = cv2.cvtColor(curImg, cv2.COLOR_BGR2GRAY)\n",
        "        #cv2.normalize(grayImage, grayImage, 0, 255, cv2.NORM_MINMAX)\n",
        "        grayImage =cv2.equalizeHist(grayImage)\n",
        "        images.append(grayImage)\n",
        "        classNo.append(count)\n",
        "    print(count, end =\" \")\n",
        "    count +=1\n",
        "print(\" \")\n",
        "images = np.array(images)\n",
        "classNo = np.array(classNo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaN-B0kTI7tp",
        "colab_type": "text"
      },
      "source": [
        "To shuffle the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awjxzrWGFvtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "np.random.shuffle(images)\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(classNo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHNk_nImDzYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "To check our loaded dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZKtHdlzDwsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "74ff0dea-9e08-493e-81ed-a95c635a32a1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "#for i in range(10):\n",
        "imgplot = plt.imshow(images[5])\n",
        "print(classNo[5])\n",
        "print(images.shape)\n",
        "print(classNo.shape)\n",
        "print(images[0].shape,images[0].min(),images[0].max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "(13928, 32, 32)\n",
            "(13928,)\n",
            "(32, 32) 0 255\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noWQXiYSSXSQSSnaRSCjZRSKhZBeJxP8DjD+Dxc6Nd1IAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTTaP5pOD5X0",
        "colab_type": "text"
      },
      "source": [
        "To split our dataset into three parts,\n",
        "train-80%,\n",
        "validation-20%,\n",
        "test-20%. \n",
        "Since we didnt normalize all the images before, we are normalizing it and checking our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb8f6akUGNuc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "b83eded4-800a-413d-cabf-6fa2eeb21d5b"
      },
      "source": [
        "testRatio = 0.2  \n",
        "validationRatio = 0.2 \n",
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validationRatio)\n",
        "\n",
        "#normalization\n",
        "X_train = X_train.astype(np.float32) / 255.0\n",
        "X_validation=X_validation.astype(np.float32) / 255.0\n",
        "X_test=X_test.astype(np.float32) / 255.0\n",
        "#checking\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "print(X_validation.shape)\n",
        "print(y_validation.shape)\n",
        "imgplot = plt.imshow(X_test[5])\n",
        "print(X_test[5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8913, 32, 32)\n",
            "(8913,)\n",
            "(2786, 32, 32)\n",
            "(2786,)\n",
            "(2229, 32, 32)\n",
            "(2229,)\n",
            "[[1.         1.         1.         ... 0.04313726 0.07843138 0.16470589]\n",
            " [1.         1.         1.         ... 0.03137255 0.14509805 0.15294118]\n",
            " [1.         1.         1.         ... 0.02745098 0.12156863 0.14509805]\n",
            " ...\n",
            " [0.25882354 0.26666668 0.25490198 ... 0.5137255  0.3764706  0.6117647 ]\n",
            " [0.25882354 0.20784314 0.17254902 ... 0.5529412  0.4117647  0.5254902 ]\n",
            " [0.04313726 0.03137255 0.01960784 ... 0.46666667 0.27450982 0.6117647 ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYUgv-m6EkSE",
        "colab_type": "text"
      },
      "source": [
        "We are converting our y to a label from 0-12 in decimal to one hot encoded form of the same, We are also testing the final shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34F37Ob7wegL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "cabd3cd6-1bc9-4b2f-c856-d1e04ec249a7"
      },
      "source": [
        "y_train = to_categorical(y_train,noOfClasses)\n",
        "y_validation = to_categorical(y_validation,noOfClasses)\n",
        "y_test = to_categorical(y_test,noOfClasses)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_validation.shape)\n",
        "print(y_train[0])\n",
        "print(y_test[0])\n",
        "print(y_validation[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8913, 13)\n",
            "(2786, 13)\n",
            "(2229, 13)\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBXbXS_XFCf4",
        "colab_type": "text"
      },
      "source": [
        "Since keras doesnt know what the input shape of the image is and also since it expects a certain shape, we are reshaping every image (the nd array)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRc9poJzSMUV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "69be754c-0dac-4885-9599-f7ba3567c502"
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, 32, 32)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 1, 32, 32)\n",
        "    X_validation=X_validation.reshape(X_validation.shape[0], 1, 32, 32)\n",
        "    print(Xtrain.shape)\n",
        "    input_shape = (1, 32, 32)\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], 32, 32, 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 32, 32, 1)\n",
        "    X_validation=X_validation.reshape(X_validation.shape[0], 32, 32, 1)\n",
        "    input_shape = (32, 32, 1)\n",
        "    \n",
        "#to test\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_validation.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8913, 32, 32, 1)\n",
            "(2786, 32, 32, 1)\n",
            "(2229, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY-iGVknGC4x",
        "colab_type": "text"
      },
      "source": [
        "We have defined two models here, we used the second"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fQwOzGettpWD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d669ef0c-7701-4a15-d9c2-60837ebad44c"
      },
      "source": [
        "def model2():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, kernel_size=5, padding='same', activation='relu', input_shape=(32, 32, 1)))\n",
        "  model.add(MaxPool2D(pool_size=2))\n",
        "  model.add(Conv2D(64, kernel_size=5, padding='same', activation='relu', input_shape=(32, 32, 1)))\n",
        "  model.add(MaxPool2D(pool_size=2))\n",
        "  model.add(Conv2D(128, kernel_size=5, padding='same', activation='relu', input_shape=(32, 32, 1)))\n",
        "  model.add(MaxPool2D(pool_size=2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(500, activation='relu'))\n",
        "  model.add(Dense(13, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\n",
        "epochs = 15\n",
        "model=model2()\n",
        "print(model.summary())\n",
        "\n",
        "h = model.fit(X_train, y_train,\n",
        "              batch_size=16, epochs = epochs,\n",
        "              validation_data = (X_validation, y_validation),\n",
        "              callbacks=[annealer], verbose=1)\n",
        "\n",
        "# STORE THE MODEL AS A PICKLE OBJECT\n",
        "pickle_out= open(\"model_trained_new.p\",\"wb\")  # wb = WRITE BYTE\n",
        "pickle.dump(model,pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 32, 32, 64)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 16, 16, 64)        102464    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 8, 8, 128)         204928    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 500)               1024500   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 13)                6513      \n",
            "=================================================================\n",
            "Total params: 1,340,069\n",
            "Trainable params: 1,340,069\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 8913 samples, validate on 2229 samples\n",
            "Epoch 1/15\n",
            "8913/8913 [==============================] - 4s 481us/step - loss: 1.3531 - acc: 0.5228 - val_loss: 0.7448 - val_acc: 0.7160\n",
            "Epoch 2/15\n",
            "8913/8913 [==============================] - 3s 367us/step - loss: 0.3105 - acc: 0.8979 - val_loss: 0.5011 - val_acc: 0.8017\n",
            "Epoch 3/15\n",
            "8913/8913 [==============================] - 3s 367us/step - loss: 0.1550 - acc: 0.9534 - val_loss: 0.1521 - val_acc: 0.9466\n",
            "Epoch 4/15\n",
            "8913/8913 [==============================] - 3s 370us/step - loss: 0.0511 - acc: 0.9852 - val_loss: 0.1065 - val_acc: 0.9668\n",
            "Epoch 5/15\n",
            "8913/8913 [==============================] - 3s 373us/step - loss: 0.0211 - acc: 0.9954 - val_loss: 0.1206 - val_acc: 0.9646\n",
            "Epoch 6/15\n",
            "8913/8913 [==============================] - 3s 371us/step - loss: 0.0173 - acc: 0.9960 - val_loss: 0.0726 - val_acc: 0.9776\n",
            "Epoch 7/15\n",
            "8913/8913 [==============================] - 3s 385us/step - loss: 0.0247 - acc: 0.9935 - val_loss: 0.0594 - val_acc: 0.9825\n",
            "Epoch 8/15\n",
            "8913/8913 [==============================] - 3s 375us/step - loss: 0.0104 - acc: 0.9971 - val_loss: 0.0465 - val_acc: 0.9856\n",
            "Epoch 9/15\n",
            "8913/8913 [==============================] - 3s 367us/step - loss: 0.0152 - acc: 0.9958 - val_loss: 0.0853 - val_acc: 0.9735\n",
            "Epoch 10/15\n",
            "8913/8913 [==============================] - 3s 373us/step - loss: 0.0072 - acc: 0.9982 - val_loss: 0.0861 - val_acc: 0.9740\n",
            "Epoch 11/15\n",
            "8913/8913 [==============================] - 3s 372us/step - loss: 0.0031 - acc: 0.9996 - val_loss: 0.0377 - val_acc: 0.9892\n",
            "Epoch 12/15\n",
            "8913/8913 [==============================] - 3s 372us/step - loss: 2.0973e-04 - acc: 1.0000 - val_loss: 0.0335 - val_acc: 0.9924\n",
            "Epoch 13/15\n",
            "8913/8913 [==============================] - 3s 366us/step - loss: 1.0384e-04 - acc: 1.0000 - val_loss: 0.0334 - val_acc: 0.9924\n",
            "Epoch 14/15\n",
            "8913/8913 [==============================] - 3s 369us/step - loss: 7.1046e-05 - acc: 1.0000 - val_loss: 0.0330 - val_acc: 0.9919\n",
            "Epoch 15/15\n",
            "8913/8913 [==============================] - 3s 377us/step - loss: 5.2749e-05 - acc: 1.0000 - val_loss: 0.0328 - val_acc: 0.9910\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y77cvhnkGPnn",
        "colab_type": "text"
      },
      "source": [
        "To print the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bPIWrt2WtpVs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c2f07cd6-6b63-4997-8e20-a157ec66d509"
      },
      "source": [
        "print('Epochs={0:d}, training accuracy={1:.5f}, validation accuracy={2:.5f}'.\\\n",
        "      format(epochs, max(h.history['acc']), max(h.history['val_acc'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs=15, training accuracy=1.00000, validation accuracy=0.99237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd2ZguKWHCST",
        "colab_type": "text"
      },
      "source": [
        "[It is advised that you download the model that is saved in the block of code above and run this in jupyter notebook or another local host. because it is better to have these audio files in local device for the next part of the code.] This part of the code is to save in the local device, the label audio using gTTS (credits to Sai Manish)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L8cfGR-HC6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from pygame import mixer\n",
        "from gtts import gTTS\n",
        "\n",
        "def label_text(file):\n",
        "    # Defining list for saving label in order from 0 to 42\n",
        "    label_list = []\n",
        "     # Reading 'csv' file and getting image's labels\n",
        "    r = pd.read_csv(file)\n",
        "    # Going through all names\n",
        "    for name in r['SignName']:\n",
        "        # Adding from every row second column with name of the label\n",
        "        label_list.append(name)\n",
        "    \n",
        "    # Returning resulted list with labels\n",
        "    return label_list\n",
        "\n",
        "\n",
        "# Getting labels\n",
        "labels = label_text(r\"C:\\Users\\Meghana Rao\\Desktop\\sih\\label_names.csv\")\n",
        "\n",
        "\n",
        "# Used for indexing\n",
        "n=range(0,12)\n",
        "#Creation of mp3 files and going all labels\n",
        "for i in n:\n",
        "    tts=gTTS(text=labels[i],lang='en-us')\n",
        "    tts.save('lable'+str(i)+'.mp3')\n",
        "#Playing the audio message\n",
        "mixer.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGEfZ9HZGYyO",
        "colab_type": "text"
      },
      "source": [
        "This part of the code doesnt work if you are using google colab because it cannot access your laptops webcam.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYbZLUjjJDce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import time\n",
        "from pygame import mixer\n",
        "import os\n",
        "\n",
        "frameWidth= 640         # CAMERA RESOLUTION\n",
        "frameHeight = 480\n",
        "brightness = 180\n",
        "threshold = 0.90         # PROBABLITY THRESHOLD\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "# SETUP THE VIDEO CAMERA\n",
        "cap = cv2.VideoCapture(0)\n",
        "cap.set(3, frameWidth)\n",
        "cap.set(4, frameHeight)\n",
        "cap.set(10, brightness)\n",
        "# IMPORT THE TRANNIED MODEL\n",
        "pickle_in=open(\"model_trained_new.p\",\"rb\")  ## rb = READ BYTE\n",
        "model=pickle.load(pickle_in)\n",
        "def label_text(file):\n",
        "    # Defining list for saving label in order from 0 to 12\n",
        "    label_list = []\n",
        "     # Reading 'csv' file and getting image's labels\n",
        "    r = pd.read_csv(file)\n",
        "    # Going through all names\n",
        "    for name in r['SignName']:\n",
        "        # Adding from every row second column with name of the label\n",
        "        label_list.append(name)\n",
        "    \n",
        "    # Returning resulted list with labels\n",
        "    return label_list\n",
        "labels = label_text(r\"C:\\Users\\Meghana Rao\\Desktop\\sih\\label_names.csv\")\n",
        "\n",
        "def grayscale(img):\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    return img\n",
        "def equalize(img):\n",
        "    img =cv2.equalizeHist(img)\n",
        "    return img\n",
        "def preprocessing(img):\n",
        "    img = grayscale(img)\n",
        "    img = equalize(img)\n",
        "    img = img/255\n",
        "    return img\n",
        "def getAudio(classNo):\n",
        "    mixer.init()\n",
        "    print(\"class: \"+labels[int(classNo)])\n",
        "    mixer.music.load('lable'+str(int(classNo))+'.mp3')\n",
        "    mixer.music.play()\n",
        "\n",
        "while True:\n",
        "\n",
        "    # READ IMAGE\n",
        "    success, imgOrignal = cap.read()\n",
        "\n",
        "    # PROCESS IMAGE\n",
        "    img = np.asarray(imgOrignal)\n",
        "    img = cv2.resize(img, (32, 32))\n",
        "    img = preprocessing(img)\n",
        "    cv2.imshow(\"Processed Image\", img)\n",
        "    img = img.reshape(1, 32, 32, 1)\n",
        "    cv2.putText(imgOrignal, \"CLASS: \" , (20, 35), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "    cv2.putText(imgOrignal, \"PROBABILITY: \", (20, 75), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "    # PREDICT IMAGE\n",
        "    predictions = model.predict(img)\n",
        "    classIndex = model.predict_classes(img)\n",
        "    probabilityValue =np.amax(predictions)\n",
        "    if probabilityValue > threshold:\n",
        "        getAudio(classIndex)\n",
        "        cv2.putText(imgOrignal,str(classIndex), (120, 35), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "        cv2.putText(imgOrignal, str(round(probabilityValue*100,2) )+\"%\", (180, 75), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "        time.sleep(2)\n",
        "    cv2.imshow(\"SIH PROJECT\", imgOrignal)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}